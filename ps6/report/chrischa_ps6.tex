%Problem Set 1 LaTeX report for TDT4200
\documentclass[fontsize=11pt, paper=a4, titlepage]{article}
\input{../../config} %config.tex file in same directory for all reports

\begin{document}

\begin{center}

{\huge Problem Set 6, Theory}\\[0.5cm]

\textsc{\LARGE TDT4200 -}\\[0.5cm]
\textsc{\large Parallel Computations}\\[1.0cm]

\begin{table}[h]
    \centering
    \begin{tabular}{c}
        \textsc{Christian Chavez}
    \end{tabular}
\end{table}

\end{center}
\vfill
\hfill \large{\today}
\clearpage

\section*{Problem 1, OpenCL}
    \begin{enumerate}[a)]

        \item

        \item
        \textit{thread} $==$ \textit{something} \\
        \textit{thread block} $==$ \textit{something} \\
        \textit{local memory} $==$ \textit{something} \\
        \textit{shared memory} $==$ \textit{something} \\

        \item

    \end{enumerate}

\section*{Problem 2, Heterogeneous computing}
    \begin{enumerate}[a)]

        \item $w$ is the total work done. $r$ can then be the work done on the
GPU, and $c$ the work done on the CPU, giving $c = w - r$, $0 < r < w$.

If, and only if, the only difference between the CPU and GPU is the time it
takes to run a computationally identical workset, then the division of labor
that results in the minimum execution time will be $1-\frac{1}{10+1}$ for the
GPU, and $1-\frac{10}{10+1}$ for the CPU.

        \begin{align*}
            T_{CPU}(w) &= T_{GPU}(w) \\
            10c &= 1r \\
            r &= 10(w-r) \\
            11r &= 10w \\
            r &= \frac{10}{11}w
        \end{align*}

        \item
        \begin{align*}
            T_{CPU}(w) &= T_{GPU}(w) + T_{in}(r) + T_{out}(w) \\
            10c &= 1r + 0.1r + 0.2r \\
            10c &= 1.3r \\
            r &= \frac{10}{11.3}w
        \end{align*}

        \item The GPU variable used in previous calculations is now represented
as $r_1$ and $r_2$, since the time it takes to execute on the CPU should be
equal to the time it takes to execute on each of the GPUs: $T_{CPU}(w) =
T_{GPU1}(w) = T_{GPU2}(w)$.

Since $T_{GPU2}(w)$ is twice as fast as $T_{GPU1}(w)$ $(T_{GPU1}(w) = w,
T_{GPU2}(w) = 2w, \Rightarrow 2w = 2*w)$, we can now express $r_1$, through the
$r_2$, and vica versa.

        \begin{align*}
            T_{CPU}(w) &= T_{GPU1}(w) \\
            10c &= r_1 \\
            r_1 &= 10(w - r_1 - r_2) \\
            r_1 &= 10(w - 3r_1) \\
            31r_1 &= 10w \\
            r_1 &= \frac{10}{31}w
        \end{align*}

        \begin{align*}
            T_{CPU}(w) &= T_{GPU2}(w) \\
            10c &= r_2 \\
            r_2 &= 10(w - 1.5r_2) \\
            16r_2 &= 10w \\
            r_2 &= \frac{10}{16}w.
        \end{align*}

        \begin{align*}
            c &= w - \frac{10}{16}w - \frac{10}{31}w \\
            c &= w - \frac{31\times 10}{31\times 16} - \frac{16\times 10}{16\times 31} \\
            c &= w - \frac{310}{496}w - \frac{160}{496}w \\
            c &= w(1-\frac{470}{496}) \\
            c &= \frac{26}{496}w = \frac{13}{248}w
        \end{align*}

    \end{enumerate}

\vfill
\hfill \large{\today}
\end{document}
